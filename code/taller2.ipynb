{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amrios80/GroceryStoreDataset/blob/master/code/taller2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TALLER 2\n",
        "\n",
        "### Objetivo:\n",
        "aplicar técnicas de machine learning, las cuales permitan descubrir insights, sugerir accionables al negocio y calcular el valor ganado.\n",
        "\n",
        "### Contexto del negocio\n",
        "Apoyo a un Supermercado Inteligente\n",
        "\n",
        "### Mision\n",
        "Mediante el uso de modelos de Machine Learning, en conjunto con técnicas de preparación de datos, se espera que usted esté en capacidad de construir el modelo que identifique los productos, y argumente el valor que generará al supermercado los resultados que obtenga.\n"
      ],
      "metadata": {
        "id": "65L8-jED_dhA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Entendimiento y preparación de los datos:\n",
        "\n",
        "Reporte de entendimiento de datos.\n",
        "\n",
        "*   Dimensiones del dataset\n",
        "*   Caracteristicas de las imagenes\n",
        "*   Indicadores importantes\n",
        "*   Intergracion de tecnicas de aumento de datos\n",
        "*   Determinacion de productos y que categorías a emplear\n"
      ],
      "metadata": {
        "id": "qlRdH4BDAivd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Dimensiones del dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "W28kD0VTzE9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "metadata=pd.read_csv('https://raw.githubusercontent.com/amrios80/GroceryStoreDataset/refs/heads/master/compressed/metadata.csv')\n",
        "#metadata[\"mode\"].value_counts()\n",
        "#print(metadata[\"extension\"].value_counts())\n",
        "print(\"numero de imagenes \" + str(metadata[metadata[\"path\"].str.contains(\".jpg\")].shape[0]) )\n",
        "print(\"archivos por modo:\" + str( metadata[\"mode\"].value_counts() ))\n"
      ],
      "metadata": {
        "id": "qjDwXFACzfUM",
        "outputId": "6326978c-a3e9-4bb9-dd04-b37db524f244",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numero de imagenes 5418\n",
            "archivos por modo:mode\n",
            "train    2639\n",
            "test     2484\n",
            "val       295\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Caracteristicas de las imagenes\n",
        "\n"
      ],
      "metadata": {
        "id": "wVy5G-4x0ipV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata[[\"size\",\"size_x\",\"size_y\",\"channels\"]].describe()"
      ],
      "metadata": {
        "id": "Hnkk2uh10pT5",
        "outputId": "3ef453d6-93ad-4793-e57c-682697f6a06b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               size       size_x       size_y  channels\n",
              "count   5418.000000  5418.000000  5418.000000    5418.0\n",
              "mean   22420.337025   348.792174   357.120709       3.0\n",
              "std     4131.906988     9.554136    31.224907       0.0\n",
              "min     9730.000000   348.000000   348.000000       3.0\n",
              "25%    19756.000000   348.000000   348.000000       3.0\n",
              "50%    22048.500000   348.000000   348.000000       3.0\n",
              "75%    24551.750000   348.000000   348.000000       3.0\n",
              "max    41049.000000   464.000000   464.000000       3.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-927d2c28-8777-4614-be0a-f15ac62839db\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>size</th>\n",
              "      <th>size_x</th>\n",
              "      <th>size_y</th>\n",
              "      <th>channels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5418.000000</td>\n",
              "      <td>5418.000000</td>\n",
              "      <td>5418.000000</td>\n",
              "      <td>5418.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>22420.337025</td>\n",
              "      <td>348.792174</td>\n",
              "      <td>357.120709</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4131.906988</td>\n",
              "      <td>9.554136</td>\n",
              "      <td>31.224907</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>9730.000000</td>\n",
              "      <td>348.000000</td>\n",
              "      <td>348.000000</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>19756.000000</td>\n",
              "      <td>348.000000</td>\n",
              "      <td>348.000000</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>22048.500000</td>\n",
              "      <td>348.000000</td>\n",
              "      <td>348.000000</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>24551.750000</td>\n",
              "      <td>348.000000</td>\n",
              "      <td>348.000000</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>41049.000000</td>\n",
              "      <td>464.000000</td>\n",
              "      <td>464.000000</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-927d2c28-8777-4614-be0a-f15ac62839db')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-927d2c28-8777-4614-be0a-f15ac62839db button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-927d2c28-8777-4614-be0a-f15ac62839db');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0c6b5c69-3251-4494-826e-6330c494687e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0c6b5c69-3251-4494-826e-6330c494687e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0c6b5c69-3251-4494-826e-6330c494687e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"metadata[[\\\"size\\\",\\\"size_x\\\",\\\"size_y\\\",\\\"channels\\\"]]\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12124.122742146588,\n        \"min\": 4131.906988292787,\n        \"max\": 41049.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          22420.337024732373,\n          22048.5,\n          5418.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"size_x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1808.4956055471546,\n        \"min\": 9.554136222418641,\n        \"max\": 5418.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          348.7921742340347,\n          464.0,\n          9.554136222418641\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"size_y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1806.4963584959467,\n        \"min\": 31.224907389989184,\n        \"max\": 5418.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          357.1207087486157,\n          464.0,\n          31.224907389989184\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"channels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1914.6434207369864,\n        \"min\": 0.0,\n        \"max\": 5418.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5418.0,\n          3.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Indicadores"
      ],
      "metadata": {
        "id": "eb0CE3Op7-vD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"cantidad de clases        :\"+str(metadata[\"class_id\"].nunique()))\n",
        "print(\"cantidad de coarse classes:\"+str(metadata[\"coarse_class_id\"].nunique()))\n",
        "print(\"Tamaño en disco           :\"+str(metadata[\"size\"].sum()/1000000 )+ \" MB \")\n",
        "print(\"numero de archivos        :\"+str(metadata.shape[0]))\n",
        "print(\"Size promedio             :\"+str(metadata[\"size\"].mean()/1000 )+ \" KB\")\n",
        "print(\"Categorias                : 3   (Fruit, Packages, Vegetables)\")"
      ],
      "metadata": {
        "id": "r3ZO-qFM76Gv",
        "outputId": "44792ce1-6de2-472a-81d8-8dcb9de00a31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cantidad de clases        :81\n",
            "cantidad de coarse classes:43\n",
            "Tamaño en disco           :121.473386 MB \n",
            "numero de archivos        :5418\n",
            "Size promedio             :22.420337024732373 KB\n",
            "Categorias                : 3   (Fruit, Packages, Vegetables)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Aumento de datos"
      ],
      "metadata": {
        "id": "7WUC6CKR8ucu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Determinacion de productos y que categorías a emplear"
      ],
      "metadata": {
        "id": "rXolhTYs8sWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_totals(df ):\n",
        "  # Calculate the amount and sum of sizes per `coarse_class_id`\n",
        "  coarse_class_summary = df.groupby('coarse_class_id').agg(\n",
        "      amount=('size', 'count'),\n",
        "      total_size=('size', 'sum')\n",
        "  ).reset_index()\n",
        "  coarse_class_summary_sorted = coarse_class_summary.sort_values(by='amount', ascending=False)\n",
        "  coarse_class_summary= coarse_class_summary_sorted.reset_index(drop=True)\n",
        "\n",
        "\n",
        "  # Calculate the amount and sum of sizes per `class_id`\n",
        "  class_summary = df.groupby('class_id').agg(\n",
        "      amount=('size', 'count'),\n",
        "      total_size=('size', 'sum')\n",
        "  ).reset_index()\n",
        "  class_summary_sorted = class_summary.sort_values(by='amount', ascending=False)\n",
        "  class_summary= class_summary_sorted.reset_index(drop=True)\n",
        "\n",
        "  # Display the results\n",
        "  print(\"Summary per coarse_class_id:\")\n",
        "  print(coarse_class_summary)\n",
        "\n",
        "  #print(\"\\nSummary per class_id:\")\n",
        "  #print(class_summary)\n",
        "\n",
        "calculate_totals(metadata)"
      ],
      "metadata": {
        "id": "eG-0xOOu8yjA",
        "outputId": "6a0754c9-c02d-43b1-88b8-815fe2fdfefe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary per coarse_class_id:\n",
            "    coarse_class_id  amount  total_size\n",
            "0                 0     573    12950909\n",
            "1                19     495    10963597\n",
            "2                27     373     8083958\n",
            "3                20     372     8572005\n",
            "4                 7     327     6734567\n",
            "5                38     237     5284242\n",
            "6                41     235     5409990\n",
            "7                13     229     5333497\n",
            "8                39     155     3062881\n",
            "9                18     143     2802642\n",
            "10               26     118     2577298\n",
            "11                9     118     2533380\n",
            "12               25     108     2360924\n",
            "13                3      96     2251217\n",
            "14                2      95     2170848\n",
            "15               23      94     1946183\n",
            "16               31      90     2011874\n",
            "17                4      88     2105191\n",
            "18                1      86     2168162\n",
            "19               36      83     2059495\n",
            "20               37      80     1696297\n",
            "21               12      78     1824398\n",
            "22               17      73     1567755\n",
            "23                8      71     1527943\n",
            "24               21      68     1509659\n",
            "25               22      68     1472758\n",
            "26                5      66     1607770\n",
            "27                6      66     1428338\n",
            "28               42      64     1471821\n",
            "29               11      60     1422793\n",
            "30               32      60     1709859\n",
            "31               16      56     1268212\n",
            "32               14      56     1617646\n",
            "33               33      50     1076055\n",
            "34               24      49     1133015\n",
            "35               35      48     1069081\n",
            "36               29      48     1106349\n",
            "37               15      44     1025113\n",
            "38               30      43      783476\n",
            "39               10      42      808100\n",
            "40               40      40     1001512\n",
            "41               34      38      933749\n",
            "42               28      35     1028827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generacion del archivo de metadata"
      ],
      "metadata": {
        "id": "ht_AEeg0888m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_train=\"https://raw.githubusercontent.com/amrios80/GroceryStoreDataset/refs/heads/master/dataset/train.txt\"\n",
        "url_test=\"https://raw.githubusercontent.com/amrios80/GroceryStoreDataset/refs/heads/master/dataset/test.txt\"\n",
        "url_val=\"https://raw.githubusercontent.com/amrios80/GroceryStoreDataset/refs/heads/master/dataset/val.txt\"\n",
        "df_train=pd.read_csv(url_train)\n",
        "df_train[\"mode\"]=\"train\"\n",
        "df_test=pd.read_csv(url_test)\n",
        "df_test[\"mode\"]=\"test\"\n",
        "df_val=pd.read_csv(url_val)\n",
        "df_val[\"mode\"]=\"val\"\n",
        "img_file_columns=[\"filename\",\"class_id\", \"coarse_class_id\", \"mode\"]\n",
        "df_train.columns=img_file_columns\n",
        "df_test.columns=img_file_columns\n",
        "df_val.columns=img_file_columns\n",
        "\n",
        "df_combined = pd.concat([df_train, df_test, df_val], axis=0, ignore_index=True)\n",
        "\n",
        "print(\"numero de archivos por modo:\")\n",
        "print(df_combined[\"mode\"].value_counts())"
      ],
      "metadata": {
        "id": "f9d4sIn9Cb76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d2c6adb-3cf2-4da1-8701-0baebcf4720e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numero de archivos por modo:\n",
            "mode\n",
            "train    2639\n",
            "test     2484\n",
            "val       295\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_files = pd.DataFrame(files)\n",
        "df_files['extension']=df_files['path'].str.split('.').str[-1]\n",
        "df_files['filename']= df_files['path'].str.split('/').str[1:].str.join('/')\n",
        "\n",
        "\n",
        "df_files.to_csv('files.csv', index=False)"
      ],
      "metadata": {
        "id": "kP23r3npDJ7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import pickle\n",
        "date_dir=\"https://raw.githubusercontent.com/amrios80/GroceryStoreDataset/refs/heads/master/dataset/\"\n",
        "# Function to load images into an array\n",
        "def load_images(data_dir, df_files, resize=False, image_x=348, image_y=348 ):\n",
        "    images = []\n",
        "    labels = []\n",
        "    metadata=[]\n",
        "    for index, row in df_files.iterrows():\n",
        "        img_path = os.path.join(data_dir, row['filename'])\n",
        "        #print(img_path)\n",
        "\n",
        "        if \"http\" in img_path:\n",
        "          url=img_path\n",
        "          response = requests.get(url)\n",
        "          if response.status_code == 200:\n",
        "            image_array = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
        "            img = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
        "            if not img.any():\n",
        "                print(f\"Error loading image: {img_path}\")\n",
        "                continue\n",
        "        else:\n",
        "          img = cv2.imread(img_path)\n",
        "          if img is None:\n",
        "              print(f\"Error loading image: {img_path}\")\n",
        "              continue\n",
        "\n",
        "        # Get dimensions\n",
        "        size_y, size_x = img.shape[:2]  # Height, Width\n",
        "        channels = img.shape[2] if len(img.shape) == 3 else 1  # Number of channels\n",
        "\n",
        "        # Determine color mode\n",
        "        color_mode = \"RGB\" if channels == 3 else \"Grayscale\"\n",
        "\n",
        "        metadata.append( {\"filename\": img_path,   \"size_x\": size_x, \"size_y\": size_y, \"channels\": channels, \"color_mode\": color_mode}   )\n",
        "        img = cv2.resize(img, (image_x, image_y))  # Resize to a fixed size\n",
        "        images.append(img)\n",
        "        labels.append(row['class_id'])\n",
        "    metadata_df=pd.DataFrame(metadata)\n",
        "    metadata_df.to_csv('image_metadata.csv', index=False)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "url_metadata= \"https://raw.githubusercontent.com/amrios80/GroceryStoreDataset/refs/heads/master/compressed/metadata.csv\"\n",
        "data_dir= \"https://raw.githubusercontent.com/amrios80/GroceryStoreDataset/refs/heads/master/dataset/\"\n",
        "df_files=pd.read_csv( url_metadata )\n",
        "df_files.columns\n",
        "images, labels = load_images( data_dir, df_files  )\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "with open('images.pkl', 'wb') as f:\n",
        "    pickle.dump(f, images)\n",
        "\n",
        "with open('labels.pkl', 'wb') as f2:\n",
        "    pickle.dump(f2, labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "9__hL9-E9aV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import requests\n",
        "\n",
        "def load_image(data_dir, filepath):\n",
        "        img_path = os.path.join(data_dir, filepath)\n",
        "        img=[]\n",
        "        if \"http\" in img_path:\n",
        "          url=img_path\n",
        "          response = requests.get(url)\n",
        "          if response.status_code == 200:\n",
        "            image_array = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
        "            img = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
        "            if not img.any():\n",
        "                print(f\"Error loading image: {img_path}\")\n",
        "        else:\n",
        "            img = cv2.imread(img_path)\n",
        "        if not img.any():\n",
        "            return []\n",
        "        return img"
      ],
      "metadata": {
        "id": "m7KDUwJIn_pL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loop_file(filename, mode=\"train\", data_dir=\"C:/sf/src/taller2/GroceryStoreDataset/dataset/\", image_x=128 , image_y=128):\n",
        "    images_array = []\n",
        "    labels_array = []\n",
        "\n",
        "    df=pd.read_csv(filename, header=None)\n",
        "    df.columns=[\"filepath\", \"class\", \"subclass\"]\n",
        "    count=0\n",
        "    flatten=True\n",
        "    normalizar=True\n",
        "    saveWithPickle=False\n",
        "    for index, row in df.iterrows():\n",
        "        count=count+1\n",
        "        filepath=row[\"filepath\"]\n",
        "        category=row[\"class\"]\n",
        "        subcategory=row[\"subclass\"]\n",
        "        img=load_image(data_dir, filepath)\n",
        "        if img.any():\n",
        "            img = cv2.resize(img, (image_x, image_y))  # Resize to a fixed size\n",
        "            images_array.append(img)\n",
        "            labels_array.append(category)\n",
        "    print(f'Procesadas {count} imagenes')\n",
        "    images=np.array(images_array)\n",
        "    labels=np.array(labels_array)\n",
        "\n",
        "    if flatten:\n",
        "        print(\"Aplanar\")\n",
        "        n_samples, height, width, channels = images.shape\n",
        "        images = images.reshape((n_samples, height * width * channels))\n",
        "    if normalizar:\n",
        "        print('Normalizar')\n",
        "        images = images / 255\n",
        "\n",
        "    X = pd.DataFrame( images )\n",
        "    if saveWithPickle:\n",
        "        X.to_pickle(os.path.join(\"C:/sf/src/taller2/\", f\"{mode}_images.pkl\"))\n",
        "    return X, labels\n"
      ],
      "metadata": {
        "id": "7t1Q12hbn_Qu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "web_source = True\n",
        "data_dir= \"\"\n",
        "url_train=\"\"\n",
        "url_test=\"\"\n",
        "url_val=\"\"\n",
        "\n",
        "\n",
        "if web_source:\n",
        "  data_dir= \"https://raw.githubusercontent.com/amrios80/GroceryStoreDataset/refs/heads/master/dataset/\"\n",
        "  url_train=\"https://raw.githubusercontent.com/amrios80/GroceryStoreDataset/refs/heads/master/dataset/train.txt\"\n",
        "  url_test=\"https://raw.githubusercontent.com/amrios80/GroceryStoreDataset/refs/heads/master/dataset/test.txt\"\n",
        "  url_val=\"https://raw.githubusercontent.com/amrios80/GroceryStoreDataset/refs/heads/master/dataset/val.txt\"\n",
        "else:\n",
        "  data_dir=\"C:/sf/src/taller2/GroceryStoreDataset/dataset/\"\n",
        "  url_train=\"C:/sf/src/taller2/GroceryStoreDataset/dataset/train.txt\"\n",
        "\n",
        "\n",
        "\n",
        "print(\"Proceso de imagenes.\")\n",
        "print('Obtener X_train')\n",
        "X_train, y_train = loop_file(filename=url_train, mode=\"train\", data_dir= data_dir)\n",
        "print('X_train size:', X_train.shape )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsVtPJ2YpOeq",
        "outputId": "63e43d0f-5fb6-44a2-a1df-81214c7045bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proceso de imagenes.\n",
            "Obtener X_train\n",
            "Procesadas 2640 imagenes\n",
            "Aplanar\n",
            "Normalizar\n",
            "X_train size: (2640, 49152)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "print('Entrenar')\n",
        "clf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "print(clf)\n",
        "\n",
        "print('Obtener X_test')\n",
        "X_test, y_test = loop_file(filename=url_test, mode=\"test\", data_dir=data_dir)\n",
        "print('X_test size:', X_test.shape )\n",
        "\n",
        "print(\"obtener predicciones\")\n",
        "y_pred = clf.predict(X_test)\n",
        "print(X_test.shape)\n",
        "\n",
        "print(\"Presentar metricas\")\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, roc_auc_score, auc\n",
        "\n",
        "print(\"Precision:\")\n",
        "print(\"- Test:\", precision_score(y_test, y_pred, average='weighted'))\n",
        "print(\"\\nRecall:\")\n",
        "print(\"- Test:\", recall_score(y_test, y_pred, average='weighted'))\n",
        "print(\"\\nF1:\")\n",
        "print(\"- Test:\", f1_score(y_test, y_pred, average='weighted'))\n",
        "print(\"\\nROC AUC:\")\n",
        "print(\"- Test:\", roc_auc_score(y_test, clf.predict_proba(X_test), multi_class='ovr'))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vuqjekNfm271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "42dff791-b78f-4627-c9b6-aa649524edfd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenar\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "RandomForestClassifier.__init__() got an unexpected keyword argument 'estimators'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-ca6b5c7896d3>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Entrenar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: RandomForestClassifier.__init__() got an unexpected keyword argument 'estimators'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Entrenamiento del modelo de machine learning\n",
        "\n",
        "Utilizando el conjunto de imágenes, construya un modelo que sea capaz de predecir el tipo de producto. Pruebe al menos dos modelos diferentes. Recuerde utilizar de la siguiente manera cada conjunto:\n",
        "\n",
        "*   train para ajustar los hiperparametros de los modelos\n",
        "*   test para seleccionar el mejor modelo\n",
        "*   valid para realizar el analisis de resultados del modelo.\n",
        "\n",
        "Aproxime su solución en el segundo nivel de categorías (Tipos de productos, i.e manzanas, aguacates, bananas, etc)."
      ],
      "metadata": {
        "id": "UJneqt0K9bwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. Modelo de clasificador Random Forest\n"
      ],
      "metadata": {
        "id": "QW9s-CBG_TUm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "at3L0GxH9bcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. Modelo de Red Neuronal"
      ],
      "metadata": {
        "id": "_Q249aW99eb1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GAclhr_v9fDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Analisis de resultados del modelo\n",
        "\n",
        "Calcule las métricas de evaluación para su modelo, y explique su significado y su valor para la empresa. Justifique la calidad de su modelo, qué elementos impactaron positivamente dichas métricas, y qué oportunidades de mejora encuentra."
      ],
      "metadata": {
        "id": "ehtA2Lbn9fu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. Modelo de clasificador Random Forest\n"
      ],
      "metadata": {
        "id": "_t9xNNNyACCH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UOnneRYYAH0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. Modelo de Red Neuronal"
      ],
      "metadata": {
        "id": "KG91sQ6yAJse"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VA5-nIm6AI42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Generacion de Valor\n",
        "\n",
        "y determine la ganancia esperada para el Supermercado con la implementación del modelo por cada predicción acertada, así como el punto a partir del cual la inversión en el modelo empezará a dejar dividendos. Realice una estimación paramétrica, haciendo explícitos todos los supuestos usando datos, incluyendo fuentes aplicables y estadísticas recientes. Para este punto debe considerar:\n",
        "\n",
        "*   Costos de tiempo asociado al registro de productos\n",
        "*   Ahorro de tiempo teorico de su modelo\n",
        "*   Costo de errores del modelo\n",
        "*   Ahorro real por prediccion acertada\n",
        "*   ROI tomando en cuenta los costos de desarrollo y depliegue del modelo\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z7W2omIuAIeE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Insights\n",
        "Redacte un informe ejecutivo o una presentación corta en donde muestre los hallazgos o insights más importantes en términos del modelo y los resultados. Ofrezca una recomendación final para el negocio."
      ],
      "metadata": {
        "id": "kbnfjiyHA_FY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qSBOUc46BGRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Bono\n",
        "\n",
        "Realice su modelo usando el nivel detallado de tipos de productos y sus marcas. (por ej. Manzanas Golden-Delicious, Granny-Smith, etc)."
      ],
      "metadata": {
        "id": "ONwj4rg9BGrN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-R_cBoy-A-px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install scikit-learn pandas numpy opencv-python\n",
        "\n",
        "\n",
        "#training\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "#data_dir = '/kaggle/input/apples/golden-delicious/'\n",
        "#labels_file = os.path.join(data_dir, 'classes.csv')\n",
        "labels_file =\"https://raw.githubusercontent.com/amrios80/GroceryStoreDataset/refs/heads/master/dataset/classes.csv\"\n",
        "label_file_columns=[\"class_name\",\"class_id\",\"coarse_class_name\",\"coarse_class_id\",\"icon_path\",\"product_description_path\"]\n",
        "\n",
        "# Read the labels\n",
        "labels_df = pd.read_csv(labels_file)\n",
        "labels_df.columns=label_file_columns\n",
        "#print(labels_df)\n",
        "\n",
        "def  load_file(data_dir='', mode=\"train\"):\n",
        "    train_file=f\"{data_dir}{mode}.txt\"\n",
        "    dftrain_file=pd.read_csv(train_file)\n",
        "    train_file_columns=[\"filename\",\"class_id\", \"coarse_class_id\"]\n",
        "    dftrain_file.columns=train_file_columns\n",
        "    return dftrain_file\n",
        "#print(dftrain_file)\n",
        "\n",
        "data_dir =\"https://raw.githubusercontent.com/amrios80/GroceryStoreDataset/refs/heads/master/dataset/\"\n",
        "\n",
        "dftrain_file=load_file(data_dir=data_dir, mode=\"train\")\n",
        "\n",
        "print('rows:' + str(dftrain_file.shape[0]))\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-28T23:33:10.628042Z",
          "iopub.execute_input": "2024-10-28T23:33:10.628839Z",
          "iopub.status.idle": "2024-10-28T23:33:19.416887Z",
          "shell.execute_reply.started": "2024-10-28T23:33:10.628792Z",
          "shell.execute_reply": "2024-10-28T23:33:19.415631Z"
        },
        "trusted": true,
        "id": "c_ukxBIa74EF",
        "outputId": "a03783ff-e29f-447e-eff7-994becc3d242",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rows:2639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load images into an array\n",
        "def load_images(data_dir, df_files, image_x=348, image_y=348 ):\n",
        "    images = []\n",
        "    labels = []\n",
        "    metadata=[]\n",
        "    for index, row in df_files.iterrows():\n",
        "        img_path = os.path.join(data_dir, row['filename'])\n",
        "        #print(img_path)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        # Get dimensions\n",
        "        size_y, size_x = img.shape[:2]  # Height, Width\n",
        "        channels = img.shape[2] if len(img.shape) == 3 else 1  # Number of channels\n",
        "\n",
        "        # Determine color mode\n",
        "        color_mode = \"RGB\" if channels == 3 else \"Grayscale\"\n",
        "\n",
        "        metadata.append( {\"filename\": img_path,   \"size_x\": size_x, \"size_y\": size_y, \"channels\": channels, \"color_mode\": color_mode}   )\n",
        "        img = cv2.resize(img, (image_x, image_y))  # Resize to a fixed size\n",
        "        images.append(img)\n",
        "        labels.append(row['class_id'])\n",
        "\n",
        "\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "\n",
        "def preprocess_dataset(data_dir='', mode=\"train\" , normalize=False, flatten=False, image_x=348, image_y=348 ):\n",
        "    dftrain_file = load_file(data_dir, mode)\n",
        "    images, labels = load_images(data_dir, dftrain_file , image_x, image_y )\n",
        "    # Normalize the images\n",
        "    # This line normalizes the pixel values of the images by dividing them by 255.0. This scales the pixel values from the original range (typically 0-255 for RGB images) to the range 0-1, which is a common normalization technique for neural networks.\n",
        "    if normalize:\n",
        "        images = images / 255.0\n",
        "    # Flatten the images for the classifier\n",
        "    #This reshapes the images from their original shape\n",
        "    # (likely (n_samples, height, width, channels)) to a flat 2D array.\n",
        "    # The new shape is (n_samples, height * width * channels), where:\n",
        "    # height * width * channels represents the total number of pixels in each image.\n",
        "    # n_samples is the number of images in the dataset.\n",
        "    if flatten:\n",
        "        n_samples, height, width, channels = images.shape\n",
        "        print('before shaping:')\n",
        "        print(images.shape)\n",
        "        print( n_samples, height, width, channels )\n",
        "        images = images.reshape((n_samples, height * width * channels))\n",
        "        print('after reshaping:')\n",
        "        print(images.shape)\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "def preprocess_dataset_no_flattening(data_dir='', mode=\"train\" ):\n",
        "    dftrain_file = load_file(data_dir, mode)\n",
        "    images, labels = load_images(data_dir, dftrain_file, image_x=128, image_y=128 )\n",
        "    # Normalize the images\n",
        "    # This line normalizes the pixel values of the images by dividing them by 255.0. This scales the pixel values from the original range (typically 0-255 for RGB images) to the range 0-1, which is a common normalization technique for neural networks.\n",
        "    images = images / 255.0\n",
        "    print(images.shape)\n",
        "    return images, labels\n",
        "\n",
        "X_train, y_train = preprocess_dataset( data_dir,\"train\" )\n",
        "print(X_train)\n",
        "print(X_train.shape)\n",
        "print(y_train)\n",
        "\n",
        "X_test, y_test = preprocess_dataset( data_dir,\"test\" )\n",
        "\n",
        "\n",
        "# Encode the labels if necessary\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# le = LabelEncoder()\n",
        "# labels = le.fit_transform(labels)\n",
        "\n",
        "# Split the data\n",
        "#X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.0, random_state=42)\n",
        "#X_train =images\n",
        "#y_train =labels\n",
        "\n",
        "print(X_train.shape)\n",
        "\n",
        "###############\n",
        "\n",
        "# Initialize the classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "06a-MxD5-ip1",
        "outputId": "ac11735e-c624-452d-f246-169e8bd45733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-43d21f40c7f5>\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_dataset\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-43d21f40c7f5>\u001b[0m in \u001b[0;36mpreprocess_dataset\u001b[0;34m(data_dir, mode, normalize, flatten, image_x, image_y)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m348\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m348\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mdftrain_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdftrain_file\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mimage_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_y\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Normalize the images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# This line normalizes the pixel values of the images by dividing them by 255.0. This scales the pixel values from the original range (typically 0-255 for RGB images) to the range 0-1, which is a common normalization technique for neural networks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-43d21f40c7f5>\u001b[0m in \u001b[0;36mload_images\u001b[0;34m(data_dir, df_files, image_x, image_y)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Get dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0msize_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Height, Width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# Number of channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize the classifier\n",
        "xgb_clf = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = xgb_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'XGBoost Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-28T23:23:12.572640Z",
          "iopub.execute_input": "2024-10-28T23:23:12.573092Z",
          "iopub.status.idle": "2024-10-28T23:28:14.238742Z",
          "shell.execute_reply.started": "2024-10-28T23:23:12.573048Z",
          "shell.execute_reply": "2024-10-28T23:28:14.237191Z"
        },
        "trusted": true,
        "id": "c02bLRql74EH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "\n",
        "X_train, y_train = preprocess_dataset_no_flattening( data_dir,\"train\" )\n",
        "X_test, y_test = preprocess_dataset_no_flattening( data_dir,\"test\" )\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')  # Assuming 10 classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'CNN Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-28T23:33:24.709776Z",
          "iopub.execute_input": "2024-10-28T23:33:24.710655Z",
          "iopub.status.idle": "2024-10-28T23:34:13.055423Z",
          "shell.execute_reply.started": "2024-10-28T23:33:24.710605Z",
          "shell.execute_reply": "2024-10-28T23:34:13.054214Z"
        },
        "trusted": true,
        "id": "Io8MqXDp74EI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Initialize the classifier\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=rf_clf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "\n",
        "# Fit the model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and accuracy\n",
        "best_params = grid_search.best_params_\n",
        "best_accuracy = grid_search.best_score_\n",
        "print(f'Best Parameters: {best_params}')\n",
        "print(f'Best Accuracy: {best_accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-28T20:50:10.756112Z",
          "iopub.execute_input": "2024-10-28T20:50:10.757446Z",
          "iopub.status.idle": "2024-10-28T20:52:28.496577Z",
          "shell.execute_reply.started": "2024-10-28T20:50:10.757393Z",
          "shell.execute_reply": "2024-10-28T20:52:28.494959Z"
        },
        "trusted": true,
        "id": "qo-2mzuy74EI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Initialize individual classifiers\n",
        "clf1 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf2 = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "clf3 = LogisticRegression(random_state=42)\n",
        "\n",
        "# Initialize the Voting Classifier\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('rf', clf1), ('xgb', clf2), ('lr', clf3)], voting='soft')\n",
        "\n",
        "# Train the classifier\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = voting_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Voting Classifier Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-28T21:21:21.434391Z",
          "iopub.execute_input": "2024-10-28T21:21:21.434975Z",
          "iopub.status.idle": "2024-10-28T21:21:21.523854Z",
          "shell.execute_reply.started": "2024-10-28T21:21:21.434923Z",
          "shell.execute_reply": "2024-10-28T21:21:21.522014Z"
        },
        "trusted": true,
        "id": "bTPgwu7d74EJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "5. Feature Engineering\n",
        "Improving the quality of your features can significantly boost model performance. This includes creating new features, transforming existing ones, and selecting the most relevant features.\n",
        "\n",
        "6. Data Augmentation\n",
        "For image data, augmenting your dataset by applying transformations like rotations, flips, and color adjustments can help improve model generalization."
      ],
      "metadata": {
        "id": "Egnold7H74EJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}